{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JX7KdzUsZ2a0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,mean_absolute_error,mean_squared_error,confusion_matrix,classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "pHQAhlkWWgfb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "q3G3jxZ4aCOy",
        "outputId": "292aab86-b1ad-4093-e857-cf4fc51fc05c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'weather_prediction_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-18f6b0d4276f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weather_prediction_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weather_prediction_dataset.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"weather_prediction_dataset.csv\")\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdKC6vIOqR7j"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUxAO4g0qTNH"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zLEyuJtqU25"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdgoTGQ6bLIH"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLV9v3yrbtYx"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkAxVRjo3-Vj"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El5tyBCizTPr"
      },
      "outputs": [],
      "source": [
        "#corr_data = df.drop('outlook',axis=1)\n",
        "#corr_data.corr().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOMcXmep4JNg"
      },
      "outputs": [],
      "source": [
        "#sns.heatmap(corr_data.corr().head(),annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K5gvIuK4R2K"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['outlook'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oSyhcqW4V-G"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=df['BASEL_humidity'],y=df['BASEL_pressure'],hue=df['BASEL_precipitation'],data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXSNdB-s5vIU"
      },
      "outputs": [],
      "source": [
        "df_BASEL = df[['BASEL_humidity', 'BASEL_pressure', 'BASEL_precipitation','BASEL_cloud_cover','BASEL_sunshine']]\n",
        "sns.pairplot(df_BASEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFDgEC3SfUPY"
      },
      "outputs": [],
      "source": [
        "features = [\"cloud_cover\", \"humidity\", \"pressure\", \"global_radiation\", \"precipitation\", \"sunshine\", \"temp_mean\", \"temp_max\"]\n",
        "base_features = [f\"BASEL_{f}\" for f in features]\n",
        "stockholm_features = [f\"STOCKHOLM_{f}\" for f in features]\n",
        "\n",
        "def outlook(row, city_prefix, noise_prob = 0.1):\n",
        "    # Convert to real units:\n",
        "    precip_mm = row[f\"{city_prefix}_precipitation\"] * 10       # mm\n",
        "    cloud_cover_pct = (row[f\"{city_prefix}_cloud_cover\"] / 8) * 100  # %\n",
        "    global_rad_wm2 = row[f\"{city_prefix}_global_radiation\"] * 100     # W/m²\n",
        "    sunshine_hours = row[f\"{city_prefix}_sunshine\"] * 0.1             # hours\n",
        "\n",
        "    if np.random.rand() < noise_prob:\n",
        "        np.random.choice([\"Rainy\", \"Cloudy\", \"Clear\", \"Uncertain\"])\n",
        "\n",
        "    # Thresholds based on converted values:\n",
        "    if precip_mm > 1.0:\n",
        "        return \"Rainy\"\n",
        "    elif cloud_cover_pct > 70 and global_rad_wm2 < 120:\n",
        "        return \"Cloudy\"\n",
        "    elif sunshine_hours > 5 and cloud_cover_pct < 30 and global_rad_wm2 > 150:\n",
        "        return \"Clear\"\n",
        "    else:\n",
        "        return \"Uncertain\"\n",
        "# Generate labels for BASEL\n",
        "city = \"BASEL\"\n",
        "df[\"outlook\"] = df.apply(lambda row: outlook(row, city), axis=1)\n",
        "safe_features = [\"humidity\", \"pressure\", \"temp_mean\", \"temp_max\", \"temp_min\"]\n",
        "X = df[[f\"{city}_{f}\" for f in safe_features]]\n",
        "y = df[\"outlook\"]\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RKLktVBkph3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8kyGRzKk8nt"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5I_7OcZk_KF"
      },
      "outputs": [],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNipOsxClAiy"
      },
      "outputs": [],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39GJbjAElCt2"
      },
      "outputs": [],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvXLP05GoGn5"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-SrJc_8UDIv"
      },
      "outputs": [],
      "source": [
        "def run_model(grid,X_train,X_test,y_train,y_test):\n",
        "  grid.fit(X_train,y_train)\n",
        "  best_model = grid.best_estimator_\n",
        "  y_pred = best_model.predict(X_test)\n",
        "  error = 1 - accuracy_score(y_test,y_pred)\n",
        "  print(f\"Best Parameters: {grid.best_params_}\")\n",
        "  print(f\"Error: {error}\")\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqs3kTW2FiJP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "cities = [\"BASEL\", \"BUDAPEST\", \"DE BILT\", \"DUSSELDORF\", \"DRESDEN\", \"HEATHROW\",\n",
        "          \"KASSEL\", \"MAASTRICHT\", \"MALMO\", \"MONTELIMAR\", \"MUNCHEN\", \"OSLO\",\n",
        "          \"PERPIGNAN\", \"ROMA\", \"STOCKHOLM\", \"SONNBLICK\", \"TOURS\", \"LJUBLJANA\"]\n",
        "\n",
        "features = [\"humidity\", \"pressure\", \"temp_mean\", \"temp_max\", \"temp_min\"]\n",
        "\n",
        "def outlook_simple(row):\n",
        "    humidity = row.get(\"humidity\", 0)\n",
        "    temp_max = row.get(\"temp_max\", 16)\n",
        "    temp_min = row.get(\"temp_min\", 7.7)\n",
        "\n",
        "    humidity_pct = humidity * 100\n",
        "    precip_mm = max(0, 15 - humidity_pct / 5)\n",
        "    temp_range = temp_max - temp_min\n",
        "    cloud_cover_pct = min(100, max(0, humidity_pct + (10 - temp_range) * 4))\n",
        "    global_rad_wm2 = max(0, 250 - cloud_cover_pct * 2)\n",
        "    sunshine_hours = max(0, 10 - cloud_cover_pct / 10)\n",
        "\n",
        "    # Relaxed Clear condition\n",
        "    if precip_mm > 3:\n",
        "        return \"Rainy\"\n",
        "    elif cloud_cover_pct > 60 and global_rad_wm2 < 150:\n",
        "        return \"Cloudy\"\n",
        "    elif sunshine_hours > 4 and cloud_cover_pct < 50 and global_rad_wm2 > 150:\n",
        "        return \"Clear\"\n",
        "    else:\n",
        "        return \"Uncertain\"\n",
        "\n",
        "all_rows = []\n",
        "\n",
        "for city in cities:\n",
        "    city_cols = [f\"{city}_{feature}\" for feature in features]\n",
        "\n",
        "    # Check if all required columns for the city exist in the DataFrame\n",
        "    if all(col in df.columns for col in city_cols):\n",
        "        # Extract city-specific data\n",
        "        city_data = df[city_cols].copy()\n",
        "\n",
        "        # Rename columns to remove city prefix for uniform processing\n",
        "        city_data.columns = features\n",
        "\n",
        "        # Add city name column\n",
        "        city_data[\"city\"] = city\n",
        "\n",
        "        # Generate outlook using your custom function\n",
        "        city_data[\"outlook\"] = city_data.apply(outlook_simple, axis=1)\n",
        "\n",
        "        all_rows.append(city_data)\n",
        "    else:\n",
        "        # Print a message for cities where data is incomplete\n",
        "        print(f\"Skipping {city} due to missing features.\")\n",
        "        missing_cols = [col for col in city_cols if col not in df.columns]\n",
        "        print(f\"Missing columns for {city}: {missing_cols}\")\n",
        "\n",
        "\n",
        "# Concatenate all valid city data into a single long-format dataframe\n",
        "df_long = pd.concat(all_rows, ignore_index=True)\n",
        "\n",
        "print(df_long.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug9hoeZpGWJv"
      },
      "outputs": [],
      "source": [
        "df_long['city'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnDp2kVi-4Jw"
      },
      "outputs": [],
      "source": [
        "df_long['outlook'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sORVw1st_VAT"
      },
      "outputs": [],
      "source": [
        "df_long.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrKaIVpWE_A1"
      },
      "outputs": [],
      "source": [
        "df_long.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQSx0Tw7FJzz"
      },
      "outputs": [],
      "source": [
        "df_long.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_long.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "RnrNOHsdKFRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOcDgvvgCWPM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJywoffBDB1f"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df_long['city'] = le.fit_transform(df_long['city'])\n",
        "df_long['outlook'] = le.fit_transform(df_long['outlook'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqaYIBmPC-9B"
      },
      "outputs": [],
      "source": [
        "X = df_long.drop(columns=['outlook','city'],axis=1)\n",
        "y = df_long['outlook']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiLbp6A4C5Mj"
      },
      "outputs": [],
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4YyywPAD8Ct"
      },
      "outputs": [],
      "source": [
        "len(X_train) , len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYoCQarrEAlc"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(class_weight='balanced',random_state=42)\n",
        "param_grid = {'criterion' : [\"gini\", \"entropy\", \"log_loss\"], 'max_depth' : [2,3,5,10]}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv = 5)\n",
        "run_model(grid,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JApbg7HBEoyE"
      },
      "outputs": [],
      "source": [
        "model_rf=RandomForestClassifier(n_estimators=100,random_state=42,class_weight='balanced')\n",
        "param_grid={'criterion':['gini', 'entropy', 'log_loss'],'max_depth':[1,5,8,10],'max_leaf_nodes':list(range(2,5))}\n",
        "grid_rf=GridSearchCV(estimator=model_rf,param_grid=param_grid)\n",
        "run_model(grid_rf,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF4_s6O1F23b"
      },
      "outputs": [],
      "source": [
        "model_boost=AdaBoostClassifier(random_state=42)\n",
        "param_grid={'n_estimators':[1,5,8,10,50,80,100]}\n",
        "grid_boost=GridSearchCV(estimator=model_boost,param_grid=param_grid)\n",
        "run_model(grid_boost,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKhuDde0GzCC"
      },
      "outputs": [],
      "source": [
        "model_gboost=GradientBoostingClassifier(random_state=42)\n",
        "param_grid={'loss':['log_loss'],'n_estimators':[1,5,8,10,50,80,100],'criterion':['friedman_mse', 'squared_error']}\n",
        "grid_gboost=GridSearchCV(estimator=model_gboost,param_grid=param_grid)\n",
        "run_model(grid_gboost,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnHtWCfkHn-5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_X_train = scaler.fit_transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "model_lr=LogisticRegression(max_iter=10000,random_state=42,class_weight='balanced')\n",
        "from sklearn.metrics import accuracy_score,mean_absolute_error,mean_squared_error,confusion_matrix,classification_report\n",
        "param_grid={'C':[1,5,8,10],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "grid_lr=GridSearchCV(estimator=model_lr,param_grid=param_grid)\n",
        "run_model(grid_lr,scaled_X_train,scaled_X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1MuoUx0IQ00"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model_knn=KNeighborsClassifier(n_neighbors=5,leaf_size=5)\n",
        "param_grid={'weights': ['uniform', 'distance'], 'algorithm' : ['auto', 'ball_tree','kd_tree', 'brute']}\n",
        "grid_knn=GridSearchCV(estimator=model_knn,param_grid=param_grid)\n",
        "run_model(grid_knn,scaled_X_train,scaled_X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R7ElZ9XIb2W"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "model_svc = SVC()\n",
        "param_grid = {'C': list(range(1, 10)), 'kernel': ['linear', 'poly', 'rbf']}\n",
        "grid_svc = GridSearchCV(estimator=model_svc, param_grid=param_grid)\n",
        "run_model(grid_svc,scaled_X_train,scaled_X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "model = run_model(grid_svc,scaled_X_train,scaled_X_test,y_train,y_test)\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(le, 'label_encoder.pkl')"
      ],
      "metadata": {
        "id": "6xTzSi5uRy61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import joblib\n",
        "\n",
        "# Load the best model (SVC) and label encoder\n",
        "svc_model = joblib.load(\"model.pkl\")     # Make sure this file exists\n",
        "le = joblib.load(\"label_encoder.pkl\")             # Label encoder for target\n",
        "\n",
        "safe_features = [\"humidity\", \"pressure\", \"temp_mean\", \"temp_max\", \"temp_min\"]\n",
        "\n",
        "def fetch_weather_data(lat, lon):\n",
        "    API_KEY = \"17b2877bc8114065a27174823251805\"\n",
        "    url = f\"http://api.weatherapi.com/v1/current.json?key={API_KEY}&q={lat},{lon}\"\n",
        "    res = requests.get(url).json()\n",
        "\n",
        "    temp_max = res['current']['temp_c']\n",
        "    temp_min = temp_max - 2\n",
        "    temp_mean = (temp_max + temp_min) / 2\n",
        "\n",
        "    weather_data = {\n",
        "        \"temp_max\": temp_max,\n",
        "        \"temp_min\": temp_min,\n",
        "        \"temp_mean\": temp_mean,\n",
        "        \"humidity\": res['current']['humidity'],\n",
        "        \"pressure\": res['current']['pressure_mb'] / 10,\n",
        "    }\n",
        "    return weather_data\n",
        "\n",
        "def xyz(mode, temp_min, temp_max, temp_mean, humidity, pressure, lat, lon):\n",
        "    if mode == \"Auto\":\n",
        "        if lat is None or lon is None:\n",
        "            return \"Please provide lat and lon\"\n",
        "        data = fetch_weather_data(lat, lon)\n",
        "    else:\n",
        "        data = {\n",
        "            \"temp_max\": temp_max,\n",
        "            \"temp_min\": temp_min,\n",
        "            \"temp_mean\": temp_mean,\n",
        "            \"humidity\": humidity,\n",
        "            \"pressure\": pressure,\n",
        "        }\n",
        "\n",
        "    for feature in safe_features:\n",
        "        if feature not in data or data[feature] is None:\n",
        "            return \"Missing data in input.\"\n",
        "\n",
        "    X = np.array([[data[f] for f in safe_features]])\n",
        "    y_pred = svc_model.predict(X)\n",
        "    return le.inverse_transform(y_pred)[0]"
      ],
      "metadata": {
        "id": "1ly9_e59PTp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xyz(\"Auto\", None, None, None, None, None, 28.6139, 77.2090)"
      ],
      "metadata": {
        "id": "0S53zIzfLybC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"Weather_Predictor\",exist_ok=True)"
      ],
      "metadata": {
        "id": "w0Pja58YcCs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Weather_Predictor/app.py\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import requests\n",
        "\n",
        "model = joblib.load(\"model.pkl\")\n",
        "le = joblib.load(\"label_encoder.pkl\")\n",
        "safe_features = [\"humidity\", \"pressure\", \"temp_mean\", \"temp_max\", \"temp_min\"]\n",
        "\n",
        "def fetch_weather_data(lat, lon):\n",
        "    API_KEY = \"17b2877bc8114065a27174823251805\"\n",
        "    url = f\"http://api.weatherapi.com/v1/current.json?key={API_KEY}&q={lat},{lon}\"\n",
        "    res = requests.get(url).json()\n",
        "\n",
        "    temp_max = res['current']['temp_c']\n",
        "    temp_min = temp_max - 2\n",
        "    temp_mean = (temp_max + temp_min) / 2\n",
        "\n",
        "    weather_data = {\n",
        "        \"temp_max\": temp_max,\n",
        "        \"temp_min\": temp_min,\n",
        "        \"temp_mean\": temp_mean,\n",
        "        \"humidity\": res['current']['humidity'],\n",
        "        \"pressure\": res['current']['pressure_mb'] / 10,\n",
        "    }\n",
        "    return weather_data\n",
        "\n",
        "def xyz(mode, temp_min, temp_max, temp_mean, humidity, pressure, lat, lon):\n",
        "    if mode == \"Auto\":\n",
        "        if lat is None or lon is None:\n",
        "            return \"Please provide lat and lon\"\n",
        "        data = fetch_weather_data(lat, lon)\n",
        "    else:\n",
        "        data = {\n",
        "            \"temp_max\": temp_max,\n",
        "            \"temp_min\": temp_min,\n",
        "            \"temp_mean\": temp_mean,\n",
        "            \"humidity\": humidity,\n",
        "            \"pressure\": pressure,\n",
        "        }\n",
        "\n",
        "    for feature in safe_features:\n",
        "        if feature not in data or data[feature] is None:\n",
        "            return \"Missing data in input.\"\n",
        "\n",
        "    X = np.array([[data[f] for f in safe_features]])\n",
        "    y_pred = model.predict(X)\n",
        "    return le.inverse_transform(y_pred)[0]\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=xyz,\n",
        "    inputs=[\n",
        "        gr.Radio([\"Manual\", \"Auto\"], label=\"Mode\"),\n",
        "        gr.Number(label=\"Temp Min (°C)\", value=20),\n",
        "        gr.Number(label=\"Temp Max (°C)\", value=25),\n",
        "        gr.Number(label=\"Temp Mean (°C)\", value=22.5),\n",
        "        gr.Number(label=\"Humidity (%)\", value=60),\n",
        "        gr.Number(label=\"Pressure (kPa)\", value=101.3),\n",
        "        gr.Number(label=\"Latitude\", value=None),\n",
        "        gr.Number(label=\"Longitude\", value=None),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Weather Condition Predictor\",\n",
        "    description=\"Predicts weather condition using either manual or automatic weather data input.\"\n",
        ")\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "QkMnyAkkTt8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Weather_Predictor/requirements.txt\n",
        "gradio\n",
        "requests\n",
        "joblib\n",
        "numpy\n",
        "pandas\n",
        "scikit-learn"
      ],
      "metadata": {
        "id": "2zrRYcAXXl5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'Weather_Predictor/model.pkl')\n",
        "joblib.dump(le, 'Weather_Predictor/label_encoder.pkl')"
      ],
      "metadata": {
        "id": "Z0inZH-edYDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Weather_Predictor/model.py"
      ],
      "metadata": {
        "id": "n-Rle3zgcXF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcdrUE1clv2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}